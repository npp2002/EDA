---
title: "Model0-2"
output: html_document
date: "2023-04-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=F)
options(scipen=999)
library(tidyverse)    #Essential Functions
```

## R Markdown

```{r}
sgf = steam_games_final %>%
  mutate(SPLIT=sample(x=c("TRAIN","TEST"),size=nrow(steam_games_final),
                  replace=T,prob=c(0.85,0.15)))
TRAIN=sgf %>%  filter(SPLIT=="TRAIN")
TEST=sgf %>% filter(SPLIT=="TEST")

TRAIN %>% 
  summarize(mean=mean(price),sd=sd(price),min=min(price),max=max(price))



# define the function to get fitted values
MODEL0 <- function(DATA, COEF) {
  FIT <- COEF[1]
}

# define the MSE and MAE functions
MSE0 <- function(DATA, COEF) {
  ERROR <- DATA$price - MODEL0(DATA, COEF)
  LOSS <- mean(ERROR^2)
  return(LOSS)
}

MAE0 <- function(DATA, COEF) {
  ERROR <- DATA$price - MODEL0(DATA, COEF)
  LOSS <- mean(abs(ERROR))
  return(LOSS)
}

# define the beta0 values
COEF0 <- tibble(
  beta0 = seq(0, 422, length = 100)
)

COEF0 %>% 
  mutate(MSE=purrr::map_dbl(beta0,MSE0,DATA=TRAIN),
         MAE=purrr::map_dbl(beta0,MAE0,DATA=TRAIN),
         rankMSE=rank(MSE),rankMAE=rank(MAE)) %>%
         filter(rankMSE<5,rankMAE<5)

# fit the model using MSE and MAE
BESTMSE0 <- optim(par = 0, fn = MSE0, DATA = TRAIN)
BESTMSE0$par
BESTMAE0 <- optim(par = 0, fn = MAE0, DATA = TRAIN)
BESTMAE0$par

#BESTMSE0$par is the vector of optimal parameters that minimize the mean squared error (MSE) when using the optim() function.

#In this case, BESTMSE0 is the output of the optim() function applied to the MSE0 function, using the TRAIN dataset as input and starting the optimization algorithm with par=0. The optim() function searches for the value of beta0 that minimizes the MSE by iteratively updating beta0 until it converges to the optimal value. The optimal value of beta0 is stored in the par component of the BESTMSE0 object.

LM0=lm(price~1,data=TRAIN)
summary(LM0)
coef(LM0)

```

```{r}
#Model1a 
#Y = Bo + B1X1 + e
#E(Y) = Bo + B1X1
#contains two variables, visualizing price vs. negative proportions

#Model for fitted values 
MODEL1A = function(DATA,COEF){
  FIT = COEF[1]+COEF[2]*DATA$neg_rate_prop
}

MSE1A = function(DATA,COEF){
  ERROR = DATA$price-MODEL1A(DATA,COEF)
  LOSS = mean(ERROR^2)
  return(LOSS)
}

MAE1A = function(DATA,COEF){
  ERROR = DATA$price-MODEL1A(DATA,COEF)
  LOSS = mean(abs(ERROR))
  return(LOSS)
}

COEF1A=tibble(
  beta0=runif(10000,0,500),
  beta1=runif(10000,0,500)
)

COEF1A %>% 
  mutate(MSE=apply(COEF1A,1,MSE1A,DATA=TRAIN),
         MAE=apply(COEF1A,1,MAE1A,DATA=TRAIN),
         rankMSE=rank(MSE),rankMAE=rank(MAE)) %>%
         filter(rankMSE<5,rankMAE<5)


ggplot(data=TRAIN) +
  geom_point(aes(x=neg_rate_prop,y=price),color="lightskyblue2") + theme_dark() +
  geom_abline(aes(intercept=2.22,slope=7.56),color="white",size=1.5)

ggplot(data=TEST) +
  geom_point(aes(x=neg_rate_prop,y=price),color="lightskyblue2") + theme_dark() +
  geom_abline(aes(intercept=2.22,slope=7.56),color="white",size=1.5)
```
```{r}
MODEL1B = function(DATA,COEF){
  FIT=COEF[1]+COEF[2]*DATA$release_year
}

MSE1B=function(DATA,COEF){
  ERROR=DATA$price-MODEL1B(DATA,COEF)
  LOSS=mean(ERROR^2)
  return(LOSS)
}

MAE1B=function(DATA,COEF){
  ERROR=DATA$price-MODEL1B(DATA,COEF)
  LOSS=mean(abs(ERROR))
  return(LOSS)
}

BESTMSE1B=optim(par=c(0,0),fn=MSE1B,DATA=TRAIN)
BESTMSE1B$par
BESTMAE1B=optim(par=c(0,0),fn=MAE1B,DATA=TRAIN)
BESTMAE1B$par

#Bo and B1
  
TRAIN %>%
  filter(price<100) %>%
  ggplot()+ geom_point(aes(x=release_year,y=price),color="lightskyblue2") +
    geom_abline(aes(intercept=441,slope=-0.215),color="white",size=1.5)+theme_dark()

TEST %>%
  filter(price<100) %>%
  ggplot()+ geom_point(aes(x=release_year,y=price),color="lightskyblue2") +
    geom_abline(aes(intercept=441,slope=-0.215),color="white",size=1.5)+theme_dark()

```
```{r}

LM2=lm(price~neg_rate_prop+release_year,data=TRAIN)
summary(LM2)
summary(LM2)$sigma #The RSE value is 8.044, however a small RSE can correspond to a large error if the range of prices is quite variable.

MSE2=function(DATA,COEF){
  ERROR=DATA$price-MODEL2(DATA,COEF)
  LOSS=mean(ERROR^2)
  return(LOSS)
}
MAE2=function(DATA,COEF){
  ERROR=DATA$price-MODEL2(DATA,COEF)
  LOSS=mean(abs(ERROR))
  return(LOSS)
}


ggplot(TRAIN, aes(x = release_year, y = price)) +
  geom_point(aes(color = neg_rate_prop),size=3) +
  scale_color_gradient2(low="blue",mid="white",high="green",midpoint=0.5) +
  labs(title = "TRAIN DATA Release Year vs. Price", x = "Release Year", y = "Price", color = "Negative Rate Proportion") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    axis.line = element_line(size = 1),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14)
  )

residuals_df <- data.frame(Residuals = resid(LM2), Predicted = predict(LM2))

# Plot the residuals against the predicted values
ggplot(residuals_df, aes(x = Predicted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Residual Plot", x = "Predicted Values", y = "Residuals")

#Based off the residual plot, we can tell that the model is overpredicting the price. This can be explained through the dense aggregation of data points above the y=0 residual line.


#generate predicted values on test set
test_preds <- predict(LM2, newdata = TEST)
residuals_df <- data.frame(Residuals = TEST$price - test_preds, Predicted = test_preds)

ggplot(residuals_df, aes(x = Predicted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Residual Plot (Test Set)", x = "Predicted Values", y = "Residuals")



MODEL2 = function(DATA,COEF){
  FIT=COEF[1]+COEF[2]*DATA$neg_rate_prop+COEF[3]*DATA$release_year
}

MODEL2.GRAPH = sgf %>% 
  mutate(predict.price=MODEL2(DATA=sgf,COEF=coef(LM2))) %>%
  ggplot()+geom_point(aes(x=price,y=predict.price,
              color=factor(SPLIT,levels=c("TRAIN","TEST"))),alpha=0.2) + 
  theme_minimal() + geom_abline(intercept=0,slope=1) +
  guides(color=guide_legend(title="Dataset")) + xlab("Price") +
  ylab("Predicted Price")
  
```


```{r}
MODELS=c("MODEL 0","MODEL 1A","MODEL 1B","MODEL 2")
MSE=c(MSE0(TEST,c(4.26)),
      MSE1A(TEST,c(2.22,7.56)),
      MSE1B(TEST,c(441,-0.22)),
      MSE2(TEST,c(371.5,-2.53,-0.18)))
MAE=c(MAE0(TEST,c(4.26)),
      MAE1A(TEST,c(2.22,7.56)),
      MAE1B(TEST,c(441,-0.22)),
      MAE2(TEST,c(371.5,-2.53,-0.18)))
COMPARE=tibble(MODELS=MODELS,MSE=MSE,MAE=MAE)
print(COMPARE)
```

