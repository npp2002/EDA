---
title: "Model for Q2"
output: html_document
date: "2023-04-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=F)
options(scipen=999)
library(tidyverse)    #Essential Functions
```

## PREPPING/VISUALIZING DATASET

How does the release year predict revenue in the top 5 most and top 5 least popular genres?

```{r}
#find frequency of each genre type 
popular <- steam_games_final %>% 
   separate_rows(genres,sep=";") %>% 
   count(genres) %>%
   arrange(desc(n))


steam_games_genre_grep = filter(steam_games_final,revenue!=0) %>%
  mutate(is.action=grepl("Action",genres)) %>%
  mutate(is.indie=grepl("Indie",genres)) %>%
  mutate(is.casual=grepl("Casual",genres)) %>%
  mutate(is.strategy=grepl("Strategy",genres)) %>%
  mutate(is.adventure=grepl("Adventure",genres)) %>%
  mutate(is.simulation=grepl("Simulation",genres)) %>%
  mutate(is.rpg=grepl("RPG",genres)) %>%
  mutate(is.earlyaccess=grepl("Early Access",genres)) %>%
  mutate(is.freetoplay=grepl("Free to Play",genres)) %>%
  mutate(is.sports=grepl("Sports",genres)) %>%
  mutate(log_revenue=log(revenue))

steam_genres_top = steam_games_genre_grep %>%
  gather(is.action:is.sports, key="Top_Genre", value="Present")

sgt_revenue <- sgt %>% 
  group_by(release_year, Top_Genre) %>% 
  summarize(total_revenue = sum(revenue))

ggplot(aes(x = release_year, y = total_revenue), data = sgt_revenue) + 
  geom_bar(aes(fill = Top_Genre), stat = "identity") +
  scale_x_continuous(breaks = seq(min(sgt$release_year), max(sgt$release_year), 1)) +
  xlab("Release Year") +
  ylab("Total Revenue") +
  ggtitle("Top 10 Genre Change over Time vs. Revenue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


##TRAIN AND TEST
```{r}
steam_games_test_train = steam_games_genre_grep %>%
  mutate(Set = sample(c("Train","Test"),size=nrow(steam_games_genre_grep),replace=TRUE,prob=c(0.8,0.2)))

train.steam = filter(steam_games_test_train,Set=="Train")
test.steam = filter(steam_games_test_train,Set=="Test")

```


## LINEAR MODELING
```{r}
lm1 = lm(revenue~is.action+is.indie+is.casual+is.strategy+is.simulation,data=train.steam)
lm2 = lm(revenue~is.action+is.indie+is.casual+is.strategy+is.simulation+is.rpg+is.earlyaccess+is.freetoplay+is.sports,data=train.steam)
lm3 = lm(revenue~is.action+is.indie+is.casual+is.strategy+is.simulation+release_year,data=train.steam)
lm4 = lm(revenue~is.action+is.indie+is.casual+release_year,data=train.steam)
lm5 = lm(revenue~is.action+is.indie+release_year,data=train.steam)
lm6 = lm(revenue~is.action+is.indie+release_year+achievements,data=train.steam)
lm7 = lm(log_revenue~is.action+is.indie+is.casual+release_year,data=train.steam)

test.steam2 = test.steam %>% 
  add_predictions(lm1,var="lm1") %>%
  add_predictions(lm2,var="lm2") %>%
  add_predictions(lm3,var="lm3") %>%
  add_predictions(lm4,var="lm4") %>%
  add_predictions(lm5,var="lm5") %>%
  add_predictions(lm6,var="lm6") %>%
  add_predictions(lm7,var="lm7") %>%
  add_residuals(lm1,var="lm1.res") %>%
  add_residuals(lm2,var="lm2.res") %>%
  add_residuals(lm3,var="lm3.res") %>%
  add_residuals(lm4,var="lm4.res") %>%
  add_residuals(lm5,var="lm5.res") %>%
  add_residuals(lm6,var="lm6.res") %>%
  add_residuals(lm7,var="lm7.res")
  

MAE.func <- function(residual){
  LOSS = mean(abs(residual))
  return(LOSS)
}

RMSE.func <- function(residual){
  LOSS <- sqrt(mean(residual^2))
}

#make html table for this

MODELS=c("MODEL 1","MODEL 2","MODEL 3","MODEL 4","MODEL 5","MODEL 6","MODEL 7")
MAE=c(MAE.func(test.steam2$lm1.res),
      MAE.func(test.steam2$lm2.res),
      MAE.func(test.steam2$lm3.res),
      MAE.func(test.steam2$lm4.res),
      MAE.func(test.steam2$lm5.res),
      MAE.func(test.steam2$lm6.res),
      MAE.func(test.steam2$lm7.res))
RMSE=c(RMSE.func(test.steam2$lm1.res),
       RMSE.func(test.steam2$lm2.res),
       RMSE.func(test.steam2$lm3.res),
       RMSE.func(test.steam2$lm4.res),
       RMSE.func(test.steam2$lm5.res),
       RMSE.func(test.steam2$lm6.res),
       RMSE.func(test.steam2$lm7.res))
COMPARE=tibble(MODELS=MODELS,RMSE=RMSE,MAE=MAE)
print(COMPARE)

#what I am noticing - it doesn't seem like genre is a good predictor variable. This could also be attributed to the test and train set, which is skewing data. Because a majority of games are released after 2000, the train set could potentially have more recent releases compared to the test. Let's try cross validation on a polynomial model?
```
Interpreting the results for Model 7. Since we took the log of our target variable, revenue, the RMSE and MAE don't represent the actual error in predicting the revenue. In order to find the actual RMSE and MAE from the log of each, you must take the exponent of each value and subtract 1 (log of 0) from each. 

##GRAPHING AND EVALUATING MODEL 7
```{r}

#evaluating model 5
predicted1 <- predict(lm5, newdata = test.steam)
actual_and_predict <- data.frame(actual = test.steam$revenue, predicted = predicted1)

ggplot(actual_and_predict, aes(x = actual, y = predicted)) +
  geom_point(alpha=0.5) +
  scale_x_log10(labels = scales::dollar_format(prefix = "$")) +
  scale_y_log10(labels = scales::dollar_format(prefix = "$")) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(x = "Actual Revenue", y = "Predicted Revenue") +
  ggtitle("Actual vs. Predicted Revenue for MODEL 5")


#evaluating model 7
predicted2 <- predict(lm7, newdata = test.steam)
actual_and_predict <- data.frame(actual = exp(test.steam$log_revenue), predicted = exp(predicted2))

ggplot(actual_and_predict, aes(x = actual, y = predicted)) +
  geom_point(alpha=0.5) +
  scale_x_log10(labels = scales::dollar_format(prefix = "$")) +
  scale_y_log10(labels = scales::dollar_format(prefix = "$")) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(x = "Actual Revenue", y = "Predicted Revenue") +
  ggtitle("Actual vs. Predicted Revenue for MODEL 7")


```

**Interpretation:** As seen by the graphs above, it is evident that MODEL 7 fits the revenue better than MODEL 5. This can be attributed to taking the logarithm of the target variable, revenue. By taking the log of the target variable, a non-linear relationship can be converted into a linear relationship. There are also a lot of outliers evident in revenue because the price of a select few games are much higher than others, affecting the revenue. Taking the log of revenue downweights the effect of such outliers, reducing extreme value impact and making the model more attuned. 

## CROSS VALIDATION USING A POLYNOMIAL MODEL
```{r}
#instead of looking at how genre itself can act as a predictor variable, maybe we can look at how revenue changes with number of achievements and release_year. We can look at the revenue with the top 5 most popular genres. The top 5 least popular genres would be interesting to look at because it directly impacts the production and marketing of certain games, but the dataset does not have enough observations for this.

#TOP 5 MOST POPULAR GENRES: Indie, Action, Casual, Adventure, Strategy

#TOP 5 LEAST POPULAR GENRES: Education, Video Production, Software Training, Audio Production, Web Publishing, 


```




##RIDGE REGRESSION USING GENRE AND POS_RATE_PROP and GENRES AS PREDICTORS 

```{r}
library(glmnet)
response_var <- steam_games_genre_grep$revenue
predictor_vars <- steam_games_genre_grep[,c("is.action","is.indie","is.casual","is.strategy","is.simulation","is.rpg","is.earlyaccess","is.freetoplay","is.sports","pos_rate_prop")]
predictor_vars.MATRIX <- as.matrix(predictor_vars)
ridge_mod <- glmnet(x=predictor_vars.MATRIX,y=response_var,alpha=0)
plot(ridge_mod,xvar="lambda")

legend("topright", legend=colnames(predictor_vars.MATRIX), col=1:ncol(predictor_vars.MATRIX), lwd=2)
```

##LASSO REGRESSION

```{r}
response_var3 <- steam_games_genre_grep$revenue
predictor_vars3 <- steam_games_genre_grep[,c("is.action","is.indie","is.casual","is.strategy","is.simulation","is.rpg","is.earlyaccess","is.freetoplay","is.sports","pos_rate_prop")]
predictor_vars3.MATRIX <- as.matrix(predictor_vars3)
lasso.mod <- glmnet(x=predictor_vars3.MATRIX,y=response_var3,alpha=1)
plot(lasso.mod,xvar="lambda",col=1:ncol(predictor_vars3.MATRIX))

legend("topright", legend=colnames(predictor_vars3.MATRIX), col=1:ncol(predictor_vars3.MATRIX), lwd=2)

#WHAT MAKES A LASSO REGRESSION COOL? it can be used to identify the most important variables that are predictive of your outcome variable, and can also help to prevent overfitting by reducing the impact of variables that may be less important.

#you can identify which variables have the highest coefficients (i.e., the most important predictors), and also see how the coefficients change as you increase the strength of the regularization penalty.

#as seen by the graph below, the highest predictors are is.action and is.indie. This makes sense because they are the most popular genres and should indicate 

#cross validation
```

##MAYBE A K-NN MODEL?

predict the revenue of a game based on a new game which falls within one genre

k=5 most similar games to this "new game"

visualization, k-NN for prediction, transform k-NN

## POLYNOMIAL MODEL?






